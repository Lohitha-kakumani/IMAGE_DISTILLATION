# ðŸ“Œ Image Sharpening using Knowledge Distillation

## ðŸš€ Overview
This project enhances image sharpness using a **Knowledge Distillation** framework. A pre-trained **Real-ESRGAN** model (Teacher) generates high-quality sharp outputs, while a lightweight **UNet** model (Student) is trained to mimic the teacherâ€™s performance.  
The final model is designed for fast, real-time image sharpening â€” ideal for video conferencing under poor network conditions.

---

## ðŸ“‚ Dataset

We use the **DIV2K** dataset:
- 800 high-resolution (HR) images split into **3200 patches** of size `256x256`
- Corresponding low-resolution (LR) versions are generated using **bicubic downscaling**

ðŸ“Ž **Dataset Location:**  
ðŸ”— [posted in kraggle  â€“ LR, HR] - https://www.kaggle.com/datasets/lohithakakumani/intel-dataset
ðŸ”— [posted in kraggle  â€“ Teacher Outputs] - https://www.kaggle.com/datasets/lohithakakumani/teacher-output
ðŸ”— [Google Drive Link] - [https://www.kaggle.com/datasets/lohithakakumani/teacher-output](https://drive.google.com/drive/folders/1bVjz7PP-XG8DhVRy-eUZQe7eRYwOG01S?usp=sharing)
---

ðŸ§  Teacher Model â€“ RealESRGAN
Used the pre-trained RealESRGAN_x4plus model for high-quality image enhancement
Ran over 3200 Low-Resolution (LR) image patches
Generated sharp and detailed outputs that act as distillation targets for training the student model
ðŸ“Ž Output Location
ðŸ“ teacher_outputs/ â€“ All outputs resized to 256x256 to match the input size for student training


ðŸ‘¶ Student Model â€“ Lightweight UNet
The student model is a compact UNet architecture trained using:
âœ… Pixel-wise L1 Loss (between prediction & HR ground truth)
âœ… Distillation Loss (between prediction & teacher output)
ðŸ“ Model gets saved as:
distilled_unet.pth

ðŸ§ª Testing the Student Model
After training, the student model is evaluated on 400 unseen LR patches.
Output images are saved to:
ðŸ“ patches/HR_Predicted/

ðŸ“ˆ SSIM Evaluation
To evaluate performance, we compute SSIM (Structural Similarity Index) between predicted and ground truth HR images.
âœ… Average SSIM Score: 0.86 (on 100 test images)

ðŸ“ Folder Structure
INTEL/
â”œâ”€â”€ dataset/                     # Contains LR, HR images of DIV2K
â”œâ”€â”€ patches/                    # Stores cropped image patches (LR, HR, and predicted outputs of student model)
â”œâ”€â”€ train/                      # Folder contains cropped images of LR,HR, and also teacher_outputs
â”œâ”€â”€ distilled_unet.pth         # âœ… Trained student model (UNet) weights
â”œâ”€â”€ RealESRGAN_x4plus.pth      # ðŸ“¥ Official RealESRGAN pretrained model file
â”œâ”€â”€ app.py                      # ðŸ“¥ test script to run the teacher model
â”œâ”€â”€ intel_teacher_model_fixed.pth # âœ… Pretrained RealESRGAN (teacher) model weights
â”œâ”€â”€ testscript.py              # ðŸ§ª Script to test student model and save predictions
â”œâ”€â”€ ssim.py                    # ðŸ“ Calculates SSIM between predictions and ground truth
â”œâ”€â”€ unet_model.py              # ðŸ§  Lightweight UNet student model architecture
â”œâ”€â”€ cropimage.py               # âœ‚ï¸ Crops HR images into 256x256 patches
â”œâ”€â”€ lowscale.py                # ðŸ”½ Generates LR images using bicubic downscaling
â”œâ”€â”€ requirements.txt           # ðŸ“š Python dependencies for the project
â”œâ”€â”€ intel.ipynb                # ðŸ““ Jupyter notebook for experimentation or demo
â”œâ”€â”€ INTEL_PRESENTATION.pptx    # ðŸ–¼ï¸ Final project presentation file
â”œâ”€â”€ Intel_report.pdf           # ðŸ“„ Final project report (includes models, methodology, results)
â”œâ”€â”€ INTEL_VIDEO_EXPLANATION.mp4 # ðŸŽ¥ Screen-recorded explanation of the project


## âš™ï¸ Environment Setup

> Python â‰¥ 3.9, CUDA GPU recommended

```bash
conda create -n intel-env-fresh python=3.9
conda activate intel-env-fresh
pip install -r requirements.txt

